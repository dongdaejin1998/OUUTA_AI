{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c852cc0",
   "metadata": {
    "id": "3c852cc0"
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules.activation import ReLU\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e9e4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    합성곱 연산, Batch Normalization, ReLU 활성함수를 연속적으로 거치도록 하는 Sequential을 return하는 함수\n",
    "\n",
    "    매개변수(Parameters)\n",
    "    ----------------------\n",
    "    in_channels: int형, 입력으로 들어오는 이미지의 채널 개수\n",
    "    out_channels: int형, 출력으로 반환할 이미지의 채널 개수\n",
    "    kernel_size: int 혹은 tuple 형, 사용할 필터의 크기 정보, default 값 3\n",
    "    stride: int 혹은 tuple 형, 스트라이드 값, defalut 값 1\n",
    "    padding: int 혹은 tuple 혹은 str형, 패딩에 대한 정보, defalut 값 0(패딩 없음)\n",
    "\n",
    "    반환 값(Returns)\n",
    "    ----------------------\n",
    "    합성곱 연산, Batch Normalization, ReLU 활성함수를 연속적으로 거치도록 하는 torch.nn.Sequential\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        # 입력받은 매개변수에 따라, 합성곱 연산을 진행\n",
    "         nn.Conv2d(in_channels,out_channels,kernel_size=kernel_size,\n",
    "                  stride=stride,padding=padding,bias=False),\n",
    "        # 배치 정규화 진행\n",
    "         nn.BatchNorm2d(out_channels) ,\n",
    "        # 활성함수인 ReLU 함수 거치기\n",
    "         nn.ReLU(inplace=True) \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f1b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeparableConv2D(in_channels, out_channels, kernel=3):\n",
    "    \"\"\"\n",
    "    Separable Convolution 연산을 진행하는 Sequential을 return하는 함수\n",
    "\n",
    "    매개변수(Parameters)\n",
    "    ----------------------\n",
    "    in_channels: int형, 입력으로 들어오는 이미지의 채널 개수\n",
    "    out_channels: int형, 출력으로 반환할 이미지의 채널 개수\n",
    "    kernel: int 혹은 tuple 형, 사용할 필터의 크기 정보, default 값 3\n",
    "    \n",
    "    반환 값(Returns)\n",
    "    ----------------------\n",
    "    Separable Convolution 연산을 진행하는 Sequential\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        # 입력받은 채널의 개수를 보존하는 형태로, 채널 수가 1인 필터를 합성곱 연산\n",
    "         nn.Conv2d(in_channels,in_channels,kernel_size=kernel,\n",
    "                  stride=1,groups=in_channels,padding=1,bias=False),\n",
    "        # 1x1 합성곱 연산 진행, 채널 개수를 원하는 출력 채널 개수로 조정\n",
    "         nn.Conv2d(in_channels,out_channels,kernel_size=1,\n",
    "                  stride=1,bias=False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0552673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualXceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel=3):\n",
    "        super(ResidualXceptionBlock, self).__init__()\n",
    "\n",
    "\n",
    "        self.depthwise_conv1 = SeparableConv2D(in_channels, out_channels, kernel)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.depthwise_conv2 = SeparableConv2D(out_channels, out_channels, kernel)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # self.padd = nn.ZeroPad2d(22)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        # self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2, padding=22, bias=False)\n",
    "        self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.residual_bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # residual branch\n",
    "        residual = self.residual_conv(x)\n",
    "        residual = self.residual_bn(residual)\n",
    "        \n",
    "        # print('input',x.shape)\n",
    "        # feature extraction branch\n",
    "        x = self.depthwise_conv1(x)\n",
    "        # print('conv1',x.shape)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.depthwise_conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        # print('conv2',x.shape)\n",
    "\n",
    "        # x = self.padd(x)\n",
    "        x = self.maxpool(x)\n",
    "        # print(x[:,:, 11:22, 11:22])\n",
    "        # print('max_pooling',x.shape)\n",
    "        # print('res',residual.shape)\n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771bd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mini_Xception(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mini_Xception, self).__init__()\n",
    "\n",
    "        # self.conv1 = conv_bn_relu(1, 32, kernel_size=3, stride=1, padding=0)\n",
    "        # self.conv2 = conv_bn_relu(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "        # self.residual_blocks = nn.ModuleList([\n",
    "        #     ResidualXceptionBlock(64 , 128).to(device),\n",
    "        #     ResidualXceptionBlock(128, 256).to(device),\n",
    "        #     ResidualXceptionBlock(256, 512).to(device),\n",
    "        #     ResidualXceptionBlock(512, 1024).to(device)            \n",
    "        # ])\n",
    "\n",
    "        # self.conv3 = nn.Conv2d(1024, 7, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "\n",
    "        self.conv1 = conv_bn_relu(1, 8, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv2 = conv_bn_relu(8, 8, kernel_size=3, stride=1, padding=0)\n",
    "        self.residual_blocks = nn.ModuleList([\n",
    "            ResidualXceptionBlock(8 , 16),\n",
    "            ResidualXceptionBlock(16, 32),\n",
    "            ResidualXceptionBlock(32, 64),\n",
    "            ResidualXceptionBlock(64, 128)            \n",
    "        ])\n",
    "        self.conv3 = nn.Conv2d(128, 7, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        for block in self.residual_blocks:\n",
    "            x = block(x)\n",
    "            # print('ith block', x.shape, block.device)\n",
    "\n",
    "        # print('blocks:',x.shape)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        # print('conv3',x.shape)\n",
    "        x = self.global_avg_pool(x)\n",
    "        # # x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d603f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(64,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*1*1,128)\n",
    "        self.fc2 = nn.Linear(128,128)\n",
    "        self.fc3=nn.Linear(128,7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #여기에 코드 작성\n",
    "        x=self.conv1(x)\n",
    "\n",
    "        x=self.conv2(x)\n",
    "\n",
    "        x=self.conv3(x)\n",
    "\n",
    "        x=self.conv4(x)\n",
    "        x=self.conv5(x)\n",
    "        x=self.flatten(x)\n",
    "\n",
    "        x=self.fc1(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da96a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=7):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet_AE(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=7):\n",
    "        super(ResNet_AE, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=3,stride=1, padding=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.conv1(x)\n",
    "        \n",
    "        decoded = self.decoder(out1)\n",
    "\n",
    "        out = F.relu(self.bn1(out1))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out, x, decoded\n",
    "\n",
    "\n",
    "def ResNet18_AE():\n",
    "    return ResNet_AE(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc4bc23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb552d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "NN                                       [128, 7]                  --\n",
      "├─Sequential: 1-1                        [128, 64, 24, 24]         --\n",
      "│    └─Conv2d: 2-1                       [128, 64, 48, 48]         640\n",
      "│    └─Conv2d: 2-2                       [128, 64, 48, 48]         36,928\n",
      "│    └─BatchNorm2d: 2-3                  [128, 64, 48, 48]         128\n",
      "│    └─ReLU: 2-4                         [128, 64, 48, 48]         --\n",
      "│    └─MaxPool2d: 2-5                    [128, 64, 24, 24]         --\n",
      "│    └─Dropout2d: 2-6                    [128, 64, 24, 24]         --\n",
      "├─Sequential: 1-2                        [128, 128, 12, 12]        --\n",
      "│    └─Conv2d: 2-7                       [128, 128, 24, 24]        73,856\n",
      "│    └─Conv2d: 2-8                       [128, 128, 24, 24]        147,584\n",
      "│    └─BatchNorm2d: 2-9                  [128, 128, 24, 24]        256\n",
      "│    └─ReLU: 2-10                        [128, 128, 24, 24]        --\n",
      "│    └─MaxPool2d: 2-11                   [128, 128, 12, 12]        --\n",
      "│    └─Dropout2d: 2-12                   [128, 128, 12, 12]        --\n",
      "├─Sequential: 1-3                        [128, 256, 6, 6]          --\n",
      "│    └─Conv2d: 2-13                      [128, 256, 12, 12]        295,168\n",
      "│    └─Conv2d: 2-14                      [128, 256, 12, 12]        590,080\n",
      "│    └─BatchNorm2d: 2-15                 [128, 256, 12, 12]        512\n",
      "│    └─ReLU: 2-16                        [128, 256, 12, 12]        --\n",
      "│    └─MaxPool2d: 2-17                   [128, 256, 6, 6]          --\n",
      "│    └─Dropout2d: 2-18                   [128, 256, 6, 6]          --\n",
      "├─Sequential: 1-4                        [128, 512, 3, 3]          --\n",
      "│    └─Conv2d: 2-19                      [128, 512, 6, 6]          1,180,160\n",
      "│    └─Conv2d: 2-20                      [128, 512, 6, 6]          2,359,808\n",
      "│    └─BatchNorm2d: 2-21                 [128, 512, 6, 6]          1,024\n",
      "│    └─ReLU: 2-22                        [128, 512, 6, 6]          --\n",
      "│    └─MaxPool2d: 2-23                   [128, 512, 3, 3]          --\n",
      "│    └─Dropout2d: 2-24                   [128, 512, 3, 3]          --\n",
      "├─Sequential: 1-5                        [128, 512, 1, 1]          --\n",
      "│    └─Conv2d: 2-25                      [128, 512, 3, 3]          2,359,808\n",
      "│    └─Conv2d: 2-26                      [128, 512, 3, 3]          2,359,808\n",
      "│    └─BatchNorm2d: 2-27                 [128, 512, 3, 3]          1,024\n",
      "│    └─ReLU: 2-28                        [128, 512, 3, 3]          --\n",
      "│    └─MaxPool2d: 2-29                   [128, 512, 1, 1]          --\n",
      "│    └─Dropout2d: 2-30                   [128, 512, 1, 1]          --\n",
      "├─Flatten: 1-6                           [128, 512]                --\n",
      "├─Linear: 1-7                            [128, 128]                65,664\n",
      "├─Linear: 1-8                            [128, 128]                16,512\n",
      "├─Linear: 1-9                            [128, 7]                  903\n",
      "==========================================================================================\n",
      "Total params: 9,489,863\n",
      "Trainable params: 9,489,863\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 65.48\n",
      "==========================================================================================\n",
      "Input size (MB): 1.18\n",
      "Forward/backward pass size (MB): 863.77\n",
      "Params size (MB): 37.96\n",
      "Estimated Total Size (MB): 902.91\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Mini_Xception                            --                        --\n",
      "├─Sequential: 1-1                        [128, 8, 46, 46]          --\n",
      "│    └─Conv2d: 2-1                       [128, 8, 46, 46]          72\n",
      "│    └─BatchNorm2d: 2-2                  [128, 8, 46, 46]          16\n",
      "│    └─ReLU: 2-3                         [128, 8, 46, 46]          --\n",
      "├─Sequential: 1-2                        [128, 8, 44, 44]          --\n",
      "│    └─Conv2d: 2-4                       [128, 8, 44, 44]          576\n",
      "│    └─BatchNorm2d: 2-5                  [128, 8, 44, 44]          16\n",
      "│    └─ReLU: 2-6                         [128, 8, 44, 44]          --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─ResidualXceptionBlock: 2-7        [128, 16, 44, 44]         --\n",
      "│    │    └─Conv2d: 3-1                  [128, 16, 44, 44]         128\n",
      "│    │    └─BatchNorm2d: 3-2             [128, 16, 44, 44]         32\n",
      "│    │    └─Sequential: 3-3              [128, 16, 44, 44]         200\n",
      "│    │    └─BatchNorm2d: 3-4             [128, 16, 44, 44]         32\n",
      "│    │    └─ReLU: 3-5                    [128, 16, 44, 44]         --\n",
      "│    │    └─Sequential: 3-6              [128, 16, 44, 44]         400\n",
      "│    │    └─BatchNorm2d: 3-7             [128, 16, 44, 44]         32\n",
      "│    │    └─MaxPool2d: 3-8               [128, 16, 44, 44]         --\n",
      "│    └─ResidualXceptionBlock: 2-8        [128, 32, 44, 44]         --\n",
      "│    │    └─Conv2d: 3-9                  [128, 32, 44, 44]         512\n",
      "│    │    └─BatchNorm2d: 3-10            [128, 32, 44, 44]         64\n",
      "│    │    └─Sequential: 3-11             [128, 32, 44, 44]         656\n",
      "│    │    └─BatchNorm2d: 3-12            [128, 32, 44, 44]         64\n",
      "│    │    └─ReLU: 3-13                   [128, 32, 44, 44]         --\n",
      "│    │    └─Sequential: 3-14             [128, 32, 44, 44]         1,312\n",
      "│    │    └─BatchNorm2d: 3-15            [128, 32, 44, 44]         64\n",
      "│    │    └─MaxPool2d: 3-16              [128, 32, 44, 44]         --\n",
      "│    └─ResidualXceptionBlock: 2-9        [128, 64, 44, 44]         --\n",
      "│    │    └─Conv2d: 3-17                 [128, 64, 44, 44]         2,048\n",
      "│    │    └─BatchNorm2d: 3-18            [128, 64, 44, 44]         128\n",
      "│    │    └─Sequential: 3-19             [128, 64, 44, 44]         2,336\n",
      "│    │    └─BatchNorm2d: 3-20            [128, 64, 44, 44]         128\n",
      "│    │    └─ReLU: 3-21                   [128, 64, 44, 44]         --\n",
      "│    │    └─Sequential: 3-22             [128, 64, 44, 44]         4,672\n",
      "│    │    └─BatchNorm2d: 3-23            [128, 64, 44, 44]         128\n",
      "│    │    └─MaxPool2d: 3-24              [128, 64, 44, 44]         --\n",
      "│    └─ResidualXceptionBlock: 2-10       [128, 128, 44, 44]        --\n",
      "│    │    └─Conv2d: 3-25                 [128, 128, 44, 44]        8,192\n",
      "│    │    └─BatchNorm2d: 3-26            [128, 128, 44, 44]        256\n",
      "│    │    └─Sequential: 3-27             [128, 128, 44, 44]        8,768\n",
      "│    │    └─BatchNorm2d: 3-28            [128, 128, 44, 44]        256\n",
      "│    │    └─ReLU: 3-29                   [128, 128, 44, 44]        --\n",
      "│    │    └─Sequential: 3-30             [128, 128, 44, 44]        17,536\n",
      "│    │    └─BatchNorm2d: 3-31            [128, 128, 44, 44]        256\n",
      "│    │    └─MaxPool2d: 3-32              [128, 128, 44, 44]        --\n",
      "├─Conv2d: 1-4                            [128, 7, 44, 44]          8,071\n",
      "├─AdaptiveAvgPool2d: 1-5                 [128, 7, 1, 1]            --\n",
      "==========================================================================================\n",
      "Total params: 56,951\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 13.75\n",
      "==========================================================================================\n",
      "Input size (MB): 1.18\n",
      "Forward/backward pass size (MB): 3648.70\n",
      "Params size (MB): 0.23\n",
      "Estimated Total Size (MB): 3650.11\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet                                   [32, 7]                   --\n",
      "├─Conv2d: 1-1                            [32, 64, 48, 48]          576\n",
      "├─BatchNorm2d: 1-2                       [32, 64, 48, 48]          128\n",
      "├─Sequential: 1-3                        [32, 256, 48, 48]         --\n",
      "│    └─Bottleneck: 2-1                   [32, 256, 48, 48]         --\n",
      "│    │    └─Conv2d: 3-1                  [32, 64, 48, 48]          4,096\n",
      "│    │    └─BatchNorm2d: 3-2             [32, 64, 48, 48]          128\n",
      "│    │    └─Conv2d: 3-3                  [32, 64, 48, 48]          36,864\n",
      "│    │    └─BatchNorm2d: 3-4             [32, 64, 48, 48]          128\n",
      "│    │    └─Conv2d: 3-5                  [32, 256, 48, 48]         16,384\n",
      "│    │    └─BatchNorm2d: 3-6             [32, 256, 48, 48]         512\n",
      "│    │    └─Sequential: 3-7              [32, 256, 48, 48]         16,896\n",
      "│    └─Bottleneck: 2-2                   [32, 256, 48, 48]         --\n",
      "│    │    └─Conv2d: 3-8                  [32, 64, 48, 48]          16,384\n",
      "│    │    └─BatchNorm2d: 3-9             [32, 64, 48, 48]          128\n",
      "│    │    └─Conv2d: 3-10                 [32, 64, 48, 48]          36,864\n",
      "│    │    └─BatchNorm2d: 3-11            [32, 64, 48, 48]          128\n",
      "│    │    └─Conv2d: 3-12                 [32, 256, 48, 48]         16,384\n",
      "│    │    └─BatchNorm2d: 3-13            [32, 256, 48, 48]         512\n",
      "│    │    └─Sequential: 3-14             [32, 256, 48, 48]         --\n",
      "│    └─Bottleneck: 2-3                   [32, 256, 48, 48]         --\n",
      "│    │    └─Conv2d: 3-15                 [32, 64, 48, 48]          16,384\n",
      "│    │    └─BatchNorm2d: 3-16            [32, 64, 48, 48]          128\n",
      "│    │    └─Conv2d: 3-17                 [32, 64, 48, 48]          36,864\n",
      "│    │    └─BatchNorm2d: 3-18            [32, 64, 48, 48]          128\n",
      "│    │    └─Conv2d: 3-19                 [32, 256, 48, 48]         16,384\n",
      "│    │    └─BatchNorm2d: 3-20            [32, 256, 48, 48]         512\n",
      "│    │    └─Sequential: 3-21             [32, 256, 48, 48]         --\n",
      "├─Sequential: 1-4                        [32, 512, 24, 24]         --\n",
      "│    └─Bottleneck: 2-4                   [32, 512, 24, 24]         --\n",
      "│    │    └─Conv2d: 3-22                 [32, 128, 48, 48]         32,768\n",
      "│    │    └─BatchNorm2d: 3-23            [32, 128, 48, 48]         256\n",
      "│    │    └─Conv2d: 3-24                 [32, 128, 24, 24]         147,456\n",
      "│    │    └─BatchNorm2d: 3-25            [32, 128, 24, 24]         256\n",
      "│    │    └─Conv2d: 3-26                 [32, 512, 24, 24]         65,536\n",
      "│    │    └─BatchNorm2d: 3-27            [32, 512, 24, 24]         1,024\n",
      "│    │    └─Sequential: 3-28             [32, 512, 24, 24]         132,096\n",
      "│    └─Bottleneck: 2-5                   [32, 512, 24, 24]         --\n",
      "│    │    └─Conv2d: 3-29                 [32, 128, 24, 24]         65,536\n",
      "│    │    └─BatchNorm2d: 3-30            [32, 128, 24, 24]         256\n",
      "│    │    └─Conv2d: 3-31                 [32, 128, 24, 24]         147,456\n",
      "│    │    └─BatchNorm2d: 3-32            [32, 128, 24, 24]         256\n",
      "│    │    └─Conv2d: 3-33                 [32, 512, 24, 24]         65,536\n",
      "│    │    └─BatchNorm2d: 3-34            [32, 512, 24, 24]         1,024\n",
      "│    │    └─Sequential: 3-35             [32, 512, 24, 24]         --\n",
      "│    └─Bottleneck: 2-6                   [32, 512, 24, 24]         --\n",
      "│    │    └─Conv2d: 3-36                 [32, 128, 24, 24]         65,536\n",
      "│    │    └─BatchNorm2d: 3-37            [32, 128, 24, 24]         256\n",
      "│    │    └─Conv2d: 3-38                 [32, 128, 24, 24]         147,456\n",
      "│    │    └─BatchNorm2d: 3-39            [32, 128, 24, 24]         256\n",
      "│    │    └─Conv2d: 3-40                 [32, 512, 24, 24]         65,536\n",
      "│    │    └─BatchNorm2d: 3-41            [32, 512, 24, 24]         1,024\n",
      "│    │    └─Sequential: 3-42             [32, 512, 24, 24]         --\n",
      "│    └─Bottleneck: 2-7                   [32, 512, 24, 24]         --\n",
      "│    │    └─Conv2d: 3-43                 [32, 128, 24, 24]         65,536\n",
      "│    │    └─BatchNorm2d: 3-44            [32, 128, 24, 24]         256\n",
      "│    │    └─Conv2d: 3-45                 [32, 128, 24, 24]         147,456\n",
      "│    │    └─BatchNorm2d: 3-46            [32, 128, 24, 24]         256\n",
      "│    │    └─Conv2d: 3-47                 [32, 512, 24, 24]         65,536\n",
      "│    │    └─BatchNorm2d: 3-48            [32, 512, 24, 24]         1,024\n",
      "│    │    └─Sequential: 3-49             [32, 512, 24, 24]         --\n",
      "├─Sequential: 1-5                        [32, 1024, 12, 12]        --\n",
      "│    └─Bottleneck: 2-8                   [32, 1024, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-50                 [32, 256, 24, 24]         131,072\n",
      "│    │    └─BatchNorm2d: 3-51            [32, 256, 24, 24]         512\n",
      "│    │    └─Conv2d: 3-52                 [32, 256, 12, 12]         589,824\n",
      "│    │    └─BatchNorm2d: 3-53            [32, 256, 12, 12]         512\n",
      "│    │    └─Conv2d: 3-54                 [32, 1024, 12, 12]        262,144\n",
      "│    │    └─BatchNorm2d: 3-55            [32, 1024, 12, 12]        2,048\n",
      "│    │    └─Sequential: 3-56             [32, 1024, 12, 12]        526,336\n",
      "│    └─Bottleneck: 2-9                   [32, 1024, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-57                 [32, 256, 12, 12]         262,144\n",
      "│    │    └─BatchNorm2d: 3-58            [32, 256, 12, 12]         512\n",
      "│    │    └─Conv2d: 3-59                 [32, 256, 12, 12]         589,824\n",
      "│    │    └─BatchNorm2d: 3-60            [32, 256, 12, 12]         512\n",
      "│    │    └─Conv2d: 3-61                 [32, 1024, 12, 12]        262,144\n",
      "│    │    └─BatchNorm2d: 3-62            [32, 1024, 12, 12]        2,048\n",
      "│    │    └─Sequential: 3-63             [32, 1024, 12, 12]        --\n",
      "│    └─Bottleneck: 2-10                  [32, 1024, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-64                 [32, 256, 12, 12]         262,144\n",
      "│    │    └─BatchNorm2d: 3-65            [32, 256, 12, 12]         512\n",
      "│    │    └─Conv2d: 3-66                 [32, 256, 12, 12]         589,824\n",
      "│    │    └─BatchNorm2d: 3-67            [32, 256, 12, 12]         512\n",
      "│    │    └─Conv2d: 3-68                 [32, 1024, 12, 12]        262,144\n",
      "│    │    └─BatchNorm2d: 3-69            [32, 1024, 12, 12]        2,048\n",
      "│    │    └─Sequential: 3-70             [32, 1024, 12, 12]        --\n",
      "│    └─Bottleneck: 2-11                  [32, 1024, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-71                 [32, 256, 12, 12]         262,144\n",
      "│    │    └─BatchNorm2d: 3-72            [32, 256, 12, 12]         512\n",
      "│    │    └─Conv2d: 3-73                 [32, 256, 12, 12]         589,824\n",
      "│    │    └─BatchNorm2d: 3-74            [32, 256, 12, 12]         512\n",
      "│    │    └─Conv2d: 3-75                 [32, 1024, 12, 12]        262,144\n",
      "│    │    └─BatchNorm2d: 3-76            [32, 1024, 12, 12]        2,048\n",
      "│    │    └─Sequential: 3-77             [32, 1024, 12, 12]        --\n",
      "│    └─Bottleneck: 2-12                  [32, 1024, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-78                 [32, 256, 12, 12]         262,144\n",
      "│    │    └─BatchNorm2d: 3-79            [32, 256, 12, 12]         512\n",
      "│    │    └─Conv2d: 3-80                 [32, 256, 12, 12]         589,824\n",
      "│    │    └─BatchNorm2d: 3-81            [32, 256, 12, 12]         512\n",
      "│    │    └─Conv2d: 3-82                 [32, 1024, 12, 12]        262,144\n",
      "│    │    └─BatchNorm2d: 3-83            [32, 1024, 12, 12]        2,048\n",
      "│    │    └─Sequential: 3-84             [32, 1024, 12, 12]        --\n",
      "│    └─Bottleneck: 2-13                  [32, 1024, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-85                 [32, 256, 12, 12]         262,144\n",
      "│    │    └─BatchNorm2d: 3-86            [32, 256, 12, 12]         512\n",
      "│    │    └─Conv2d: 3-87                 [32, 256, 12, 12]         589,824\n",
      "│    │    └─BatchNorm2d: 3-88            [32, 256, 12, 12]         512\n",
      "│    │    └─Conv2d: 3-89                 [32, 1024, 12, 12]        262,144\n",
      "│    │    └─BatchNorm2d: 3-90            [32, 1024, 12, 12]        2,048\n",
      "│    │    └─Sequential: 3-91             [32, 1024, 12, 12]        --\n",
      "├─Sequential: 1-6                        [32, 2048, 6, 6]          --\n",
      "│    └─Bottleneck: 2-14                  [32, 2048, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-92                 [32, 512, 12, 12]         524,288\n",
      "│    │    └─BatchNorm2d: 3-93            [32, 512, 12, 12]         1,024\n",
      "│    │    └─Conv2d: 3-94                 [32, 512, 6, 6]           2,359,296\n",
      "│    │    └─BatchNorm2d: 3-95            [32, 512, 6, 6]           1,024\n",
      "│    │    └─Conv2d: 3-96                 [32, 2048, 6, 6]          1,048,576\n",
      "│    │    └─BatchNorm2d: 3-97            [32, 2048, 6, 6]          4,096\n",
      "│    │    └─Sequential: 3-98             [32, 2048, 6, 6]          2,101,248\n",
      "│    └─Bottleneck: 2-15                  [32, 2048, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-99                 [32, 512, 6, 6]           1,048,576\n",
      "│    │    └─BatchNorm2d: 3-100           [32, 512, 6, 6]           1,024\n",
      "│    │    └─Conv2d: 3-101                [32, 512, 6, 6]           2,359,296\n",
      "│    │    └─BatchNorm2d: 3-102           [32, 512, 6, 6]           1,024\n",
      "│    │    └─Conv2d: 3-103                [32, 2048, 6, 6]          1,048,576\n",
      "│    │    └─BatchNorm2d: 3-104           [32, 2048, 6, 6]          4,096\n",
      "│    │    └─Sequential: 3-105            [32, 2048, 6, 6]          --\n",
      "│    └─Bottleneck: 2-16                  [32, 2048, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-106                [32, 512, 6, 6]           1,048,576\n",
      "│    │    └─BatchNorm2d: 3-107           [32, 512, 6, 6]           1,024\n",
      "│    │    └─Conv2d: 3-108                [32, 512, 6, 6]           2,359,296\n",
      "│    │    └─BatchNorm2d: 3-109           [32, 512, 6, 6]           1,024\n",
      "│    │    └─Conv2d: 3-110                [32, 2048, 6, 6]          1,048,576\n",
      "│    │    └─BatchNorm2d: 3-111           [32, 2048, 6, 6]          4,096\n",
      "│    │    └─Sequential: 3-112            [32, 2048, 6, 6]          --\n",
      "├─Linear: 1-7                            [32, 7]                   14,343\n",
      "==========================================================================================\n",
      "Total params: 23,513,543\n",
      "Trainable params: 23,513,543\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 93.36\n",
      "==========================================================================================\n",
      "Input size (MB): 0.29\n",
      "Forward/backward pass size (MB): 3954.18\n",
      "Params size (MB): 94.05\n",
      "Estimated Total Size (MB): 4048.53\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "    model1 = NN()\n",
    "    model2=Mini_Xception()\n",
    "    model3=ResNet50()\n",
    "    print(summary(model1,(128,1,48,48)))\n",
    "    print(summary(model2,(128,1,48,48)))\n",
    "    print(summary(model3,(32,1,48,48)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3763ed0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vision_model_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
